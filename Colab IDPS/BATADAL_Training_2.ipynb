{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**IDPS FOR WDS**"
      ],
      "metadata": {
        "id": "cZTKC5roDB0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Load & Explore Data"
      ],
      "metadata": {
        "id": "M6pYxMhfDAE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "id": "rDoyrBXdNozk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157e84ca-d4be-4eb5-8bfd-e4ce4f1b44ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oRn_guwC1Pr",
        "outputId": "2ffb5aa3-3885-4a09-f07c-61047987a327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-b2f67b9571c0>:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_normal = pd.read_csv(\"/content/drive/MyDrive/CWDS_DEMO/BATADAL Datasets/BATADAL_normal.csv\", parse_dates=['DATETIME'], dayfirst=True)\n",
            "<ipython-input-1-b2f67b9571c0>:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_attack = pd.read_csv(\"/content/drive/MyDrive/CWDS_DEMO/BATADAL Datasets/BATADAL_train.csv\", parse_dates=['DATETIME'], dayfirst=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8761 entries, 0 to 8760\n",
            "Data columns (total 45 columns):\n",
            " #   Column    Non-Null Count  Dtype         \n",
            "---  ------    --------------  -----         \n",
            " 0   DATETIME  8761 non-null   datetime64[ns]\n",
            " 1   L_T1      8761 non-null   float64       \n",
            " 2   L_T2      8761 non-null   float64       \n",
            " 3   L_T3      8761 non-null   float64       \n",
            " 4   L_T4      8761 non-null   float64       \n",
            " 5   L_T5      8761 non-null   float64       \n",
            " 6   L_T6      8761 non-null   float64       \n",
            " 7   L_T7      8761 non-null   float64       \n",
            " 8   F_PU1     8761 non-null   float64       \n",
            " 9   S_PU1     8761 non-null   int64         \n",
            " 10  F_PU2     8761 non-null   float64       \n",
            " 11  S_PU2     8761 non-null   int64         \n",
            " 12  F_PU3     8761 non-null   int64         \n",
            " 13  S_PU3     8761 non-null   int64         \n",
            " 14  F_PU4     8761 non-null   float64       \n",
            " 15  S_PU4     8761 non-null   int64         \n",
            " 16  F_PU5     8761 non-null   int64         \n",
            " 17  S_PU5     8761 non-null   int64         \n",
            " 18  F_PU6     8761 non-null   float64       \n",
            " 19  S_PU6     8761 non-null   int64         \n",
            " 20  F_PU7     8761 non-null   float64       \n",
            " 21  S_PU7     8761 non-null   int64         \n",
            " 22  F_PU8     8761 non-null   float64       \n",
            " 23  S_PU8     8761 non-null   int64         \n",
            " 24  F_PU9     8761 non-null   int64         \n",
            " 25  S_PU9     8761 non-null   int64         \n",
            " 26  F_PU10    8761 non-null   float64       \n",
            " 27  S_PU10    8761 non-null   int64         \n",
            " 28  F_PU11    8761 non-null   float64       \n",
            " 29  S_PU11    8761 non-null   int64         \n",
            " 30  F_V2      8761 non-null   float64       \n",
            " 31  S_V2      8761 non-null   int64         \n",
            " 32  P_J280    8761 non-null   float64       \n",
            " 33  P_J269    8761 non-null   float64       \n",
            " 34  P_J300    8761 non-null   float64       \n",
            " 35  P_J256    8761 non-null   float64       \n",
            " 36  P_J289    8761 non-null   float64       \n",
            " 37  P_J415    8761 non-null   float64       \n",
            " 38  P_J302    8761 non-null   float64       \n",
            " 39  P_J306    8761 non-null   float64       \n",
            " 40  P_J307    8761 non-null   float64       \n",
            " 41  P_J317    8761 non-null   float64       \n",
            " 42  P_J14     8761 non-null   float64       \n",
            " 43  P_J422    8761 non-null   float64       \n",
            " 44  ATT_FLAG  8761 non-null   int64         \n",
            "dtypes: datetime64[ns](1), float64(28), int64(16)\n",
            "memory usage: 3.0 MB\n",
            "None \n",
            "\n",
            "Attack Data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4177 entries, 0 to 4176\n",
            "Data columns (total 45 columns):\n",
            " #   Column    Non-Null Count  Dtype         \n",
            "---  ------    --------------  -----         \n",
            " 0   DATETIME  4177 non-null   datetime64[ns]\n",
            " 1   L_T1      4177 non-null   float64       \n",
            " 2   L_T2      4177 non-null   float64       \n",
            " 3   L_T3      4177 non-null   float64       \n",
            " 4   L_T4      4177 non-null   float64       \n",
            " 5   L_T5      4177 non-null   float64       \n",
            " 6   L_T6      4177 non-null   float64       \n",
            " 7   L_T7      4177 non-null   float64       \n",
            " 8   F_PU1     4177 non-null   float64       \n",
            " 9   S_PU1     4177 non-null   int64         \n",
            " 10  F_PU2     4177 non-null   float64       \n",
            " 11  S_PU2     4177 non-null   int64         \n",
            " 12  F_PU3     4177 non-null   int64         \n",
            " 13  S_PU3     4177 non-null   int64         \n",
            " 14  F_PU4     4177 non-null   float64       \n",
            " 15  S_PU4     4177 non-null   int64         \n",
            " 16  F_PU5     4177 non-null   int64         \n",
            " 17  S_PU5     4177 non-null   int64         \n",
            " 18  F_PU6     4177 non-null   float64       \n",
            " 19  S_PU6     4177 non-null   int64         \n",
            " 20  F_PU7     4177 non-null   float64       \n",
            " 21  S_PU7     4177 non-null   int64         \n",
            " 22  F_PU8     4177 non-null   float64       \n",
            " 23  S_PU8     4177 non-null   int64         \n",
            " 24  F_PU9     4177 non-null   int64         \n",
            " 25  S_PU9     4177 non-null   int64         \n",
            " 26  F_PU10    4177 non-null   float64       \n",
            " 27  S_PU10    4177 non-null   int64         \n",
            " 28  F_PU11    4177 non-null   float64       \n",
            " 29  S_PU11    4177 non-null   int64         \n",
            " 30  F_V2      4177 non-null   float64       \n",
            " 31  S_V2      4177 non-null   int64         \n",
            " 32  P_J280    4177 non-null   float64       \n",
            " 33  P_J269    4177 non-null   float64       \n",
            " 34  P_J300    4177 non-null   float64       \n",
            " 35  P_J256    4177 non-null   float64       \n",
            " 36  P_J289    4177 non-null   float64       \n",
            " 37  P_J415    4177 non-null   float64       \n",
            " 38  P_J302    4177 non-null   float64       \n",
            " 39  P_J306    4177 non-null   float64       \n",
            " 40  P_J307    4177 non-null   float64       \n",
            " 41  P_J317    4177 non-null   float64       \n",
            " 42  P_J14     4177 non-null   float64       \n",
            " 43  P_J422    4177 non-null   float64       \n",
            " 44  ATT_FLAG  4177 non-null   int64         \n",
            "dtypes: datetime64[ns](1), float64(28), int64(16)\n",
            "memory usage: 1.4 MB\n",
            "None \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(             DATETIME      L_T1      L_T2      L_T3      L_T4      L_T5  \\\n",
              " 0 2014-01-06 00:00:00  0.509730  2.049003  3.191145  2.792634  2.656091   \n",
              " 1 2014-01-06 01:00:00  0.412580  2.009072  3.642565  2.831673  3.126387   \n",
              " 2 2014-01-06 02:00:00  0.320112  1.986093  4.140192  3.256733  3.574601   \n",
              " 3 2014-01-06 03:00:00  0.332879  2.009203  4.673478  3.744497  3.952379   \n",
              " 4 2014-01-06 04:00:00  0.483496  2.089049  5.237937  4.409456  3.504676   \n",
              " \n",
              "        L_T6      L_T7      F_PU1  S_PU1  ...     P_J256     P_J289     P_J415  \\\n",
              " 0  5.316831  1.562321  98.998444      1  ...  87.605774  26.495605  84.206619   \n",
              " 1  5.494855  1.852043  99.095901      1  ...  89.448341  26.487326  85.900085   \n",
              " 2  5.500000  2.246126  98.420959      1  ...  91.056114  26.487364  86.582474   \n",
              " 3  5.500000  3.203573  97.575172      1  ...  92.594353  26.575815  88.020546   \n",
              " 4  5.500000  4.439714  97.351059      1  ...  94.473099  26.723457  90.422462   \n",
              " \n",
              "       P_J302     P_J306     P_J307     P_J317      P_J14     P_J422  ATT_FLAG  \n",
              " 0  18.901676  81.983734  18.791777  67.125603  29.387470  28.487471         0  \n",
              " 1  18.849329  82.150589  18.739643  67.178696  29.354256  28.454256         0  \n",
              " 2  19.597170  83.988579  19.496712  72.425293  29.354538  28.454538         0  \n",
              " 3  26.028486  64.670486  25.922703  76.275040  29.449951  28.549952         0  \n",
              " 4  26.209970  64.746620  26.104692  76.703529  29.574265  28.674263         0  \n",
              " \n",
              " [5 rows x 45 columns],\n",
              "              DATETIME  L_T1  L_T2  L_T3  L_T4  L_T5  L_T6  L_T7  F_PU1  S_PU1  \\\n",
              " 0 2016-07-04 00:00:00  2.44  5.24  3.19  4.10  2.86  5.50  4.39  93.63      1   \n",
              " 1 2016-07-04 01:00:00  2.66  4.53  3.20  4.18  3.29  5.44  4.53  89.41      1   \n",
              " 2 2016-07-04 02:00:00  3.11  3.66  3.66  4.21  3.87  5.15  3.22  89.88      1   \n",
              " 3 2016-07-04 03:00:00  3.62  3.04  4.17  4.04  3.56  4.98  2.40  88.10      1   \n",
              " 4 2016-07-04 04:00:00  4.08  2.68  4.73  3.20  3.11  5.39  3.46  87.01      1   \n",
              " \n",
              "    ...  P_J256  P_J289  P_J415  P_J302  P_J306  P_J307  P_J317  P_J14  P_J422  \\\n",
              " 0  ...   70.00   28.22   85.87   21.69   82.72   21.58   71.99  39.33   29.64   \n",
              " 1  ...   87.73   24.45   84.87   29.81   86.62   29.81   59.76  42.17   26.15   \n",
              " 2  ...   89.29   23.90   87.11   29.85   87.64   29.85   58.50  42.00   25.56   \n",
              " 3  ...   91.98   27.10   68.75   31.60   64.25   31.47   72.30  43.24   28.38   \n",
              " 4  ...   92.11   26.76   68.74   32.30   64.23   32.17   72.53  44.00   28.04   \n",
              " \n",
              "    ATT_FLAG  \n",
              " 0         0  \n",
              " 1         0  \n",
              " 2         0  \n",
              " 3         0  \n",
              " 4         0  \n",
              " \n",
              " [5 rows x 45 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load datasets (Upload manually in Colab first)\n",
        "df_normal = pd.read_csv(\"/content/drive/MyDrive/CWDS_DEMO/BATADAL Datasets/BATADAL_normal.csv\", parse_dates=['DATETIME'], dayfirst=True)\n",
        "df_attack = pd.read_csv(\"/content/drive/MyDrive/CWDS_DEMO/BATADAL Datasets/BATADAL_train.csv\", parse_dates=['DATETIME'], dayfirst=True)\n",
        "\n",
        "# Display basic info\n",
        "print(\"Normal Data:\")\n",
        "print(df_normal.info(), \"\\n\")\n",
        "print(\"Attack Data:\")\n",
        "print(df_attack.info(), \"\\n\")\n",
        "\n",
        "# Display first few rows\n",
        "df_normal.head(), df_attack.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 2: Data Preprocessing"
      ],
      "metadata": {
        "id": "DDYeAYS3FZkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop timestamps\n",
        "df_normal = df_normal.drop(columns=['DATETIME'])\n",
        "df_attack = df_attack.drop(columns=['DATETIME'])\n",
        "\n",
        "# Separate features and labels\n",
        "X_normal = df_normal.drop(columns=['ATT_FLAG'])\n",
        "y_normal = df_normal['ATT_FLAG']\n",
        "\n",
        "X_attack = df_attack.drop(columns=['ATT_FLAG'])\n",
        "y_attack = df_attack['ATT_FLAG']\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_normal_scaled = scaler.fit_transform(X_normal)\n",
        "X_attack_scaled = scaler.transform(X_attack)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "X_normal = pd.DataFrame(X_normal_scaled, columns=X_normal.columns)\n",
        "X_attack = pd.DataFrame(X_attack_scaled, columns=X_attack.columns)\n",
        "\n",
        "print(\"Data successfully normalized!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97n1T4MZFXMf",
        "outputId": "bb789943-2c3a-44d0-fcaa-270734d799ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully normalized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 3: Handle Class Imbalance"
      ],
      "metadata": {
        "id": "QgXba6QjFewS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Balance the dataset using SMOTE\n",
        "smote = SMOTE(sampling_strategy=0.5, random_state=42)  # Adjust ratio as needed\n",
        "X_balanced, y_balanced = smote.fit_resample(X_attack, y_attack)\n",
        "\n",
        "print(\"Balanced Data Distribution:\")\n",
        "print(pd.Series(y_balanced).value_counts())\n",
        "\n",
        "# Split into train & test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training Set: {X_train.shape}, Testing Set: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkSpVOrYFfvc",
        "outputId": "a96ef47c-fc69-4932-ba64-c9feb814972d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Data Distribution:\n",
            "ATT_FLAG\n",
            "0    3685\n",
            "1    1842\n",
            "Name: count, dtype: int64\n",
            "Training Set: (4421, 43), Testing Set: (1106, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Train Anomaly Detection Models"
      ],
      "metadata": {
        "id": "N19krqTgFt6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Train Isolation Forest\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "iso_forest.fit(X_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = iso_forest.predict(X_test)\n",
        "y_pred = [1 if p == -1 else 0 for p in y_pred]  # Convert to attack labels (1 = attack)\n",
        "\n",
        "# Evaluate\n",
        "print(\"ğŸ”¹ Isolation Forest Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkPIJyo8FuiA",
        "outputId": "8d22d003-0edf-4161-e6fc-0a1896d498dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ Isolation Forest Performance:\n",
            "[[729  12]\n",
            " [329  36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.98      0.81       741\n",
            "           1       0.75      0.10      0.17       365\n",
            "\n",
            "    accuracy                           0.69      1106\n",
            "   macro avg       0.72      0.54      0.49      1106\n",
            "weighted avg       0.71      0.69      0.60      1106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Improve Isolation Forest"
      ],
      "metadata": {
        "id": "_biMdbbNGlIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-train Isolation Forest with different contamination level\n",
        "iso_forest = IsolationForest(n_estimators=200, contamination=0.1, random_state=42)\n",
        "iso_forest.fit(X_train)\n",
        "\n",
        "# Predict again\n",
        "y_pred = iso_forest.predict(X_test)\n",
        "y_pred = [1 if p == -1 else 0 for p in y_pred]\n",
        "\n",
        "# Evaluate again\n",
        "print(\"ğŸ”¹ Improved Isolation Forest Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bp2ppJIGl1G",
        "outputId": "3a22661c-f3db-4620-b6d1-853a4071bf0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ Improved Isolation Forest Performance:\n",
            "[[713  28]\n",
            " [284  81]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.96      0.82       741\n",
            "           1       0.74      0.22      0.34       365\n",
            "\n",
            "    accuracy                           0.72      1106\n",
            "   macro avg       0.73      0.59      0.58      1106\n",
            "weighted avg       0.72      0.72      0.66      1106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Try Local Outlier Factor (LOF)"
      ],
      "metadata": {
        "id": "tQY3YYRCGtmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Train Local Outlier Factor\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1, novelty=True)\n",
        "lof.fit(X_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_lof = lof.predict(X_test)\n",
        "y_pred_lof = [1 if p == -1 else 0 for p in y_pred_lof]\n",
        "\n",
        "# Evaluate\n",
        "print(\"ğŸ”¹ Local Outlier Factor Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred_lof))\n",
        "print(classification_report(y_test, y_pred_lof))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_n-cNw5GuKA",
        "outputId": "ddfe512e-3876-4150-989a-c8bf9c7d0753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ Local Outlier Factor Performance:\n",
            "[[704  37]\n",
            " [315  50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.95      0.80       741\n",
            "           1       0.57      0.14      0.22       365\n",
            "\n",
            "    accuracy                           0.68      1106\n",
            "   macro avg       0.63      0.54      0.51      1106\n",
            "weighted avg       0.65      0.68      0.61      1106\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Train an AutoEncoder (Deep Learning Approach)"
      ],
      "metadata": {
        "id": "X3evvO09G1L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# Define AutoEncoder model\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 8  # Dimension of compressed representation\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoded = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
        "decoded = Dense(input_dim, activation=\"sigmoid\")(encoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the AutoEncoder\n",
        "autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, shuffle=True, validation_data=(X_test, X_test))\n",
        "\n",
        "# Get reconstruction error\n",
        "X_test_reconstructed = autoencoder.predict(X_test)\n",
        "reconstruction_error = np.mean(np.abs(X_test - X_test_reconstructed), axis=1)\n",
        "\n",
        "# Define threshold based on training reconstruction error\n",
        "threshold = np.percentile(reconstruction_error, 95)  # Top 5% as anomalies\n",
        "\n",
        "# Predict anomalies\n",
        "y_pred_ae = [1 if e > threshold else 0 for e in reconstruction_error]\n",
        "\n",
        "# Evaluate\n",
        "print(\"ğŸ”¹ AutoEncoder Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred_ae))\n",
        "print(classification_report(y_test, y_pred_ae))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYzUd1XWG12B",
        "outputId": "815d89e1-4a91-41cf-8631-74e62f1f03ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1466 - val_loss: 0.0854\n",
            "Epoch 2/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0771 - val_loss: 0.0615\n",
            "Epoch 3/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0594 - val_loss: 0.0503\n",
            "Epoch 4/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0485 - val_loss: 0.0414\n",
            "Epoch 5/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0407 - val_loss: 0.0345\n",
            "Epoch 6/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0341 - val_loss: 0.0298\n",
            "Epoch 7/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0300 - val_loss: 0.0262\n",
            "Epoch 8/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0263 - val_loss: 0.0232\n",
            "Epoch 9/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0234 - val_loss: 0.0204\n",
            "Epoch 10/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0203 - val_loss: 0.0177\n",
            "Epoch 11/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0177 - val_loss: 0.0156\n",
            "Epoch 12/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0156 - val_loss: 0.0143\n",
            "Epoch 13/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0143 - val_loss: 0.0135\n",
            "Epoch 14/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0134 - val_loss: 0.0128\n",
            "Epoch 15/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0130 - val_loss: 0.0124\n",
            "Epoch 16/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0124 - val_loss: 0.0121\n",
            "Epoch 17/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0125 - val_loss: 0.0119\n",
            "Epoch 18/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0121 - val_loss: 0.0117\n",
            "Epoch 19/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0120 - val_loss: 0.0115\n",
            "Epoch 20/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0117 - val_loss: 0.0114\n",
            "Epoch 21/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0114 - val_loss: 0.0112\n",
            "Epoch 22/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0118 - val_loss: 0.0112\n",
            "Epoch 23/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0114 - val_loss: 0.0110\n",
            "Epoch 24/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0110 - val_loss: 0.0110\n",
            "Epoch 25/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0116 - val_loss: 0.0109\n",
            "Epoch 26/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0108\n",
            "Epoch 27/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0114 - val_loss: 0.0107\n",
            "Epoch 28/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0110 - val_loss: 0.0107\n",
            "Epoch 29/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0112 - val_loss: 0.0106\n",
            "Epoch 30/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0107 - val_loss: 0.0105\n",
            "Epoch 31/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0112 - val_loss: 0.0105\n",
            "Epoch 32/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0111 - val_loss: 0.0104\n",
            "Epoch 33/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0104\n",
            "Epoch 34/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0104\n",
            "Epoch 35/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0104 - val_loss: 0.0103\n",
            "Epoch 36/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0108 - val_loss: 0.0102\n",
            "Epoch 37/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0109 - val_loss: 0.0102\n",
            "Epoch 38/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0101\n",
            "Epoch 39/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0106 - val_loss: 0.0101\n",
            "Epoch 40/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0103 - val_loss: 0.0101\n",
            "Epoch 41/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0100\n",
            "Epoch 42/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0105 - val_loss: 0.0099\n",
            "Epoch 43/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0099\n",
            "Epoch 44/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0101 - val_loss: 0.0099\n",
            "Epoch 45/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0101 - val_loss: 0.0099\n",
            "Epoch 46/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0104 - val_loss: 0.0098\n",
            "Epoch 47/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0097\n",
            "Epoch 48/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101 - val_loss: 0.0098\n",
            "Epoch 49/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - val_loss: 0.0097\n",
            "Epoch 50/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0103 - val_loss: 0.0097\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "ğŸ”¹ AutoEncoder Performance:\n",
            "[[729  12]\n",
            " [321  44]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.98      0.81       741\n",
            "           1       0.79      0.12      0.21       365\n",
            "\n",
            "    accuracy                           0.70      1106\n",
            "   macro avg       0.74      0.55      0.51      1106\n",
            "weighted avg       0.72      0.70      0.61      1106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "\n",
        "# Define Improved AutoEncoder\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 16\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoded = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
        "encoded = BatchNormalization()(encoded)\n",
        "encoded = Dropout(0.2)(encoded)\n",
        "\n",
        "encoded = Dense(8, activation=\"relu\")(encoded)\n",
        "encoded = BatchNormalization()(encoded)\n",
        "encoded = Dropout(0.2)(encoded)\n",
        "\n",
        "decoded = Dense(encoding_dim, activation=\"relu\")(encoded)\n",
        "decoded = BatchNormalization()(decoded)\n",
        "decoded = Dense(input_dim, activation=\"sigmoid\")(decoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the AutoEncoder\n",
        "autoencoder.fit(X_train, X_train, epochs=100, batch_size=64, shuffle=True, validation_data=(X_test, X_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5ouNa5jLEvs",
        "outputId": "7bb054c4-b495-4a86-9ca7-8d641b1008ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1731 - val_loss: 0.1435\n",
            "Epoch 2/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1391 - val_loss: 0.1131\n",
            "Epoch 3/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1093 - val_loss: 0.0774\n",
            "Epoch 4/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0797 - val_loss: 0.0562\n",
            "Epoch 5/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0620 - val_loss: 0.0456\n",
            "Epoch 6/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0531 - val_loss: 0.0398\n",
            "Epoch 7/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0490 - val_loss: 0.0348\n",
            "Epoch 8/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0440 - val_loss: 0.0311\n",
            "Epoch 9/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0410 - val_loss: 0.0277\n",
            "Epoch 10/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0244\n",
            "Epoch 11/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0218\n",
            "Epoch 12/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0347 - val_loss: 0.0204\n",
            "Epoch 13/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0319 - val_loss: 0.0184\n",
            "Epoch 14/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0309 - val_loss: 0.0173\n",
            "Epoch 15/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0297 - val_loss: 0.0165\n",
            "Epoch 16/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0295 - val_loss: 0.0158\n",
            "Epoch 17/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0281 - val_loss: 0.0154\n",
            "Epoch 18/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0288 - val_loss: 0.0149\n",
            "Epoch 19/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0145\n",
            "Epoch 20/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0144\n",
            "Epoch 21/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0141\n",
            "Epoch 22/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.0140\n",
            "Epoch 23/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0138\n",
            "Epoch 24/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0265 - val_loss: 0.0137\n",
            "Epoch 25/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0261 - val_loss: 0.0136\n",
            "Epoch 26/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0264 - val_loss: 0.0135\n",
            "Epoch 27/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0135\n",
            "Epoch 28/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0134\n",
            "Epoch 29/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0258 - val_loss: 0.0133\n",
            "Epoch 30/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0132\n",
            "Epoch 31/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0255 - val_loss: 0.0131\n",
            "Epoch 32/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0131\n",
            "Epoch 33/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0131\n",
            "Epoch 34/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0131\n",
            "Epoch 35/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - val_loss: 0.0130\n",
            "Epoch 36/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0255 - val_loss: 0.0128\n",
            "Epoch 37/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0243 - val_loss: 0.0128\n",
            "Epoch 38/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0249 - val_loss: 0.0129\n",
            "Epoch 39/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0246 - val_loss: 0.0130\n",
            "Epoch 40/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0239 - val_loss: 0.0128\n",
            "Epoch 41/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0248 - val_loss: 0.0127\n",
            "Epoch 42/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0128\n",
            "Epoch 43/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0240 - val_loss: 0.0127\n",
            "Epoch 44/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0127\n",
            "Epoch 45/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0127\n",
            "Epoch 46/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0127\n",
            "Epoch 47/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0234 - val_loss: 0.0126\n",
            "Epoch 48/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0126\n",
            "Epoch 49/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0126\n",
            "Epoch 50/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0238 - val_loss: 0.0125\n",
            "Epoch 51/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0126\n",
            "Epoch 52/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0233 - val_loss: 0.0126\n",
            "Epoch 53/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0124\n",
            "Epoch 54/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0124\n",
            "Epoch 55/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0124\n",
            "Epoch 56/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0123\n",
            "Epoch 57/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0124\n",
            "Epoch 58/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0124\n",
            "Epoch 59/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0123\n",
            "Epoch 60/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0230 - val_loss: 0.0123\n",
            "Epoch 61/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0233 - val_loss: 0.0123\n",
            "Epoch 62/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0232 - val_loss: 0.0123\n",
            "Epoch 63/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0233 - val_loss: 0.0123\n",
            "Epoch 64/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0238 - val_loss: 0.0122\n",
            "Epoch 65/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0237 - val_loss: 0.0121\n",
            "Epoch 66/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0232 - val_loss: 0.0123\n",
            "Epoch 67/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0232 - val_loss: 0.0122\n",
            "Epoch 68/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0233 - val_loss: 0.0123\n",
            "Epoch 69/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0241 - val_loss: 0.0122\n",
            "Epoch 70/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0122\n",
            "Epoch 71/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0122\n",
            "Epoch 72/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0121\n",
            "Epoch 73/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0122\n",
            "Epoch 74/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0121\n",
            "Epoch 75/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0231 - val_loss: 0.0121\n",
            "Epoch 76/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0122\n",
            "Epoch 77/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0237 - val_loss: 0.0121\n",
            "Epoch 78/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0121\n",
            "Epoch 79/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0121\n",
            "Epoch 80/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0121\n",
            "Epoch 81/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0221 - val_loss: 0.0121\n",
            "Epoch 82/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0237 - val_loss: 0.0121\n",
            "Epoch 83/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0234 - val_loss: 0.0120\n",
            "Epoch 84/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0119\n",
            "Epoch 85/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0230 - val_loss: 0.0119\n",
            "Epoch 86/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0231 - val_loss: 0.0120\n",
            "Epoch 87/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0119\n",
            "Epoch 88/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0119\n",
            "Epoch 89/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0228 - val_loss: 0.0120\n",
            "Epoch 90/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0224 - val_loss: 0.0119\n",
            "Epoch 91/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0228 - val_loss: 0.0119\n",
            "Epoch 92/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0230 - val_loss: 0.0118\n",
            "Epoch 93/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0236 - val_loss: 0.0118\n",
            "Epoch 94/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0227 - val_loss: 0.0118\n",
            "Epoch 95/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0227 - val_loss: 0.0118\n",
            "Epoch 96/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0118\n",
            "Epoch 97/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0117\n",
            "Epoch 98/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0221 - val_loss: 0.0117\n",
            "Epoch 99/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0117\n",
            "Epoch 100/100\n",
            "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0117\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b46213705d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get reconstructed test data\n",
        "X_test_reconstructed = autoencoder.predict(X_test)\n",
        "\n",
        "# Compute reconstruction error (Mean Absolute Error)\n",
        "reconstruction_error = np.mean(np.abs(X_test - X_test_reconstructed), axis=1)\n",
        "\n",
        "# Display error statistics\n",
        "print(\"Reconstruction Error - Min:\", reconstruction_error.min())\n",
        "print(\"Reconstruction Error - Max:\", reconstruction_error.max())\n",
        "print(\"Reconstruction Error - Mean:\", reconstruction_error.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1HRkfCJMJSf",
        "outputId": "1652f557-e817-438f-fc1d-5cb6cc6bcb08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Reconstruction Error - Min: 0.02307900416000903\n",
            "Reconstruction Error - Max: 0.16736069433254083\n",
            "Reconstruction Error - Mean: 0.057874663224861914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define threshold for anomalies (95th percentile)\n",
        "threshold = np.percentile(reconstruction_error, 95)\n",
        "\n",
        "print(f\"Anomaly Detection Threshold: {threshold}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u2kBkKRMSPb",
        "outputId": "b3cade87-bd66-4d7e-b735-e06bd0e79d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anomaly Detection Threshold: 0.08272723026539991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify anomalies\n",
        "y_pred_ae = [1 if e > threshold else 0 for e in reconstruction_error]\n",
        "\n",
        "# Evaluate AutoEncoder Performance\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(\"ğŸ”¹ AutoEncoder (Improved) Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred_ae))\n",
        "print(classification_report(y_test, y_pred_ae))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTuRY5zQMXkC",
        "outputId": "c883f45e-485e-4bb2-abd1-4366612802d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ AutoEncoder (Improved) Performance:\n",
            "[[728  13]\n",
            " [322  43]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.98      0.81       741\n",
            "           1       0.77      0.12      0.20       365\n",
            "\n",
            "    accuracy                           0.70      1106\n",
            "   macro avg       0.73      0.55      0.51      1106\n",
            "weighted avg       0.72      0.70      0.61      1106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape Data for LSTM"
      ],
      "metadata": {
        "id": "L8EMEgR7M5tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine a valid time step size\n",
        "time_steps = 2  # Start with 2 and try increasing if necessary\n",
        "input_dim = X_train.shape[1] // time_steps  # Compute new feature size\n",
        "\n",
        "# Ensure feature count is divisible by time_steps\n",
        "X_train_trimmed = X_train.iloc[:, :input_dim * time_steps]\n",
        "X_test_trimmed = X_test.iloc[:, :input_dim * time_steps]\n",
        "\n",
        "# Reshape\n",
        "X_train_lstm = np.reshape(X_train_trimmed.values, (X_train_trimmed.shape[0], time_steps, -1))\n",
        "X_test_lstm = np.reshape(X_test_trimmed.values, (X_test_trimmed.shape[0], time_steps, -1))\n",
        "\n",
        "print(\"âœ… LSTM Input Shape:\", X_train_lstm.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vrq4ViEOaVk",
        "outputId": "44010897-7bc3-4f6a-8c95-199da057d2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… LSTM Input Shape: (4421, 2, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define time steps (how many past observations to use)\n",
        "time_steps = 5\n",
        "\n",
        "# Reshape training and test data\n",
        "X_train_lstm = np.reshape(X_train.values, (X_train.shape[0], time_steps, X_train.shape[1] // time_steps))\n",
        "X_test_lstm = np.reshape(X_test.values, (X_test.shape[0], time_steps, X_test.shape[1] // time_steps))\n",
        "\n",
        "print(\"LSTM Input Shape:\", X_train_lstm.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "NtZF-IDpM6Un",
        "outputId": "fb3419ce-c914-403c-ecda-ec61b11aa128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 190103 into shape (4421,5,8)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-5b4f52cfb361>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Reshape training and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_test_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    283\u001b[0m            [5, 6]])\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 190103 into shape (4421,5,8)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define & Train LSTM AutoEncode"
      ],
      "metadata": {
        "id": "jaHUZC79M9q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, RepeatVector, TimeDistributed\n",
        "\n",
        "\n",
        "# Define LSTM AutoEncoder Model\n",
        "input_dim = X_train_lstm.shape[2]  # Number of features per time step\n",
        "\n",
        "input_layer = Input(shape=(time_steps, input_dim))\n",
        "encoded = LSTM(64, activation=\"relu\", return_sequences=True)(input_layer)\n",
        "encoded = LSTM(32, activation=\"relu\", return_sequences=False)(encoded)\n",
        "\n",
        "decoded = RepeatVector(time_steps)(encoded)\n",
        "decoded = LSTM(32, activation=\"relu\", return_sequences=True)(decoded)\n",
        "decoded = LSTM(64, activation=\"relu\", return_sequences=True)(decoded)\n",
        "decoded = TimeDistributed(Dense(input_dim))(decoded)\n",
        "\n",
        "lstm_autoencoder = Model(input_layer, decoded)\n",
        "lstm_autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Train LSTM AutoEncoder\n",
        "lstm_autoencoder.fit(X_train_lstm, X_train_lstm, epochs=50, batch_size=32, validation_data=(X_test_lstm, X_test_lstm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r48D3SZbM-Rd",
        "outputId": "24b607ba-2605-44b0-e0b2-f970307dc3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.2453 - val_loss: 0.0808\n",
            "Epoch 2/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0793 - val_loss: 0.0559\n",
            "Epoch 3/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0477 - val_loss: 0.0296\n",
            "Epoch 4/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0273 - val_loss: 0.0219\n",
            "Epoch 5/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0202 - val_loss: 0.0146\n",
            "Epoch 6/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0143 - val_loss: 0.0127\n",
            "Epoch 7/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0128 - val_loss: 0.0114\n",
            "Epoch 8/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0116 - val_loss: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0102 - val_loss: 0.0090\n",
            "Epoch 10/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0087 - val_loss: 0.0079\n",
            "Epoch 11/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0080 - val_loss: 0.0071\n",
            "Epoch 12/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0070 - val_loss: 0.0066\n",
            "Epoch 13/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0061 - val_loss: 0.0053\n",
            "Epoch 14/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0050\n",
            "Epoch 15/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0043\n",
            "Epoch 16/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 17/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0043\n",
            "Epoch 18/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0031\n",
            "Epoch 19/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0036\n",
            "Epoch 20/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 21/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 22/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0024 - val_loss: 0.0025\n",
            "Epoch 23/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 24/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 25/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 26/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 27/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 28/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 29/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 30/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 31/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 32/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 33/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 34/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 35/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 36/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 37/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0015\n",
            "Epoch 38/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 39/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 40/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0012\n",
            "Epoch 41/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0014\n",
            "Epoch 42/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 43/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 9.7601e-04 - val_loss: 9.5919e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 9.2857e-04 - val_loss: 9.8097e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.2318e-04 - val_loss: 9.9197e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 9.1706e-04 - val_loss: 8.7405e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.4179e-04 - val_loss: 9.8086e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.0951e-04 - val_loss: 9.1823e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 8.1835e-04 - val_loss: 0.0011\n",
            "Epoch 50/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 8.5355e-04 - val_loss: 8.0622e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7feaa8f9ecd0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Reconstruction Errors"
      ],
      "metadata": {
        "id": "rdDrZE3uNEXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get reconstructed test data\n",
        "X_test_lstm_reconstructed = lstm_autoencoder.predict(X_test_lstm)\n",
        "\n",
        "# Compute reconstruction error (Mean Absolute Error)\n",
        "reconstruction_error_lstm = np.mean(np.abs(X_test_lstm - X_test_lstm_reconstructed), axis=(1, 2))\n",
        "\n",
        "# Display error statistics\n",
        "print(\"LSTM Reconstruction Error - Min:\", reconstruction_error_lstm.min())\n",
        "print(\"LSTM Reconstruction Error - Max:\", reconstruction_error_lstm.max())\n",
        "print(\"LSTM Reconstruction Error - Mean:\", reconstruction_error_lstm.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXEeRKDaNGfR",
        "outputId": "f7a8c34d-1831-4a59-9d3e-e804df4652bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "LSTM Reconstruction Error - Min: 0.009282635609927658\n",
            "LSTM Reconstruction Error - Max: 0.08792045810955587\n",
            "LSTM Reconstruction Error - Mean: 0.019263287455908905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Threshold & Detect Anomalies"
      ],
      "metadata": {
        "id": "VwWiccoONJ2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define anomaly threshold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "threshold_lstm = np.percentile(reconstruction_error_lstm, 95)\n",
        "\n",
        "print(f\"LSTM Anomaly Detection Threshold: {threshold_lstm}\")\n",
        "\n",
        "# Predict anomalies\n",
        "y_pred_lstm = [1 if e > threshold_lstm else 0 for e in reconstruction_error_lstm]\n",
        "\n",
        "# Evaluate Performance\n",
        "print(\"ğŸ”¹ LSTM AutoEncoder Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred_lstm))\n",
        "print(classification_report(y_test, y_pred_lstm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNptG7h4NKoB",
        "outputId": "29435b59-d5c3-4bc2-8fd6-77dbd1cce3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Anomaly Detection Threshold: 0.032597031693717804\n",
            "ğŸ”¹ LSTM AutoEncoder Performance:\n",
            "[[737   4]\n",
            " [313  52]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.99      0.82       741\n",
            "           1       0.93      0.14      0.25       365\n",
            "\n",
            "    accuracy                           0.71      1106\n",
            "   macro avg       0.82      0.57      0.54      1106\n",
            "weighted avg       0.78      0.71      0.63      1106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust threshold dynamically (90th percentile instead of 95th)\n",
        "new_threshold_lstm = np.percentile(reconstruction_error_lstm, 90)  # Lower threshold\n",
        "\n",
        "# Predict anomalies\n",
        "y_pred_lstm_adjusted = [1 if e > new_threshold_lstm else 0 for e in reconstruction_error_lstm]\n",
        "\n",
        "# Evaluate again\n",
        "print(\"ğŸ”¹ LSTM AutoEncoder (Adjusted Threshold) Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred_lstm_adjusted))\n",
        "print(classification_report(y_test, y_pred_lstm_adjusted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufPP-RTHVO9j",
        "outputId": "e76777e0-5f38-4d3d-b01a-485087c5faa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ LSTM AutoEncoder (Adjusted Threshold) Performance:\n",
            "[[723  18]\n",
            " [272  93]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.98      0.83       741\n",
            "           1       0.84      0.25      0.39       365\n",
            "\n",
            "    accuracy                           0.74      1106\n",
            "   macro avg       0.78      0.62      0.61      1106\n",
            "weighted avg       0.76      0.74      0.69      1106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "# Define Bi-Directional LSTM AutoEncoder\n",
        "input_layer = Input(shape=(time_steps, input_dim))\n",
        "encoded = Bidirectional(LSTM(64, activation=\"relu\", return_sequences=True))(input_layer)\n",
        "encoded = Bidirectional(LSTM(32, activation=\"relu\", return_sequences=False))(encoded)\n",
        "\n",
        "decoded = RepeatVector(time_steps)(encoded)\n",
        "decoded = Bidirectional(LSTM(32, activation=\"relu\", return_sequences=True))(decoded)\n",
        "decoded = Bidirectional(LSTM(64, activation=\"relu\", return_sequences=True))(decoded)\n",
        "decoded = TimeDistributed(Dense(input_dim))(decoded)\n",
        "\n",
        "bilstm_autoencoder = Model(input_layer, decoded)\n",
        "bilstm_autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Train the Bi-Directional LSTM\n",
        "bilstm_autoencoder.fit(X_train_lstm, X_train_lstm, epochs=50, batch_size=32, validation_data=(X_test_lstm, X_test_lstm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVKm9RxrWZo_",
        "outputId": "e0a2fce4-e639-4a88-d4b1-e13f3e19c055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 26ms/step - loss: 0.2088 - val_loss: 0.0780\n",
            "Epoch 2/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0765 - val_loss: 0.0454\n",
            "Epoch 3/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0355 - val_loss: 0.0164\n",
            "Epoch 4/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0146 - val_loss: 0.0107\n",
            "Epoch 5/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.0098 - val_loss: 0.0076\n",
            "Epoch 6/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0072 - val_loss: 0.0058\n",
            "Epoch 7/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0053 - val_loss: 0.0044\n",
            "Epoch 8/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0033\n",
            "Epoch 9/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0031 - val_loss: 0.0032\n",
            "Epoch 10/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 11/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 12/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 13/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 14/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 15/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 16/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 17/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 18/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.4978e-04 - val_loss: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 9.1283e-04 - val_loss: 9.7581e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.4699e-04 - val_loss: 9.3996e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.3011e-04 - val_loss: 8.1999e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7.0343e-04 - val_loss: 7.1334e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 7.1079e-04 - val_loss: 7.1755e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.5170e-04 - val_loss: 7.5818e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.4555e-04 - val_loss: 7.2414e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.0544e-04 - val_loss: 9.3081e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.0910e-04 - val_loss: 7.1151e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.9086e-04 - val_loss: 5.7836e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 5.0616e-04 - val_loss: 5.7477e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.2599e-04 - val_loss: 5.7014e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.0243e-04 - val_loss: 5.3349e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 4.9256e-04 - val_loss: 5.9747e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 4.9255e-04 - val_loss: 5.1496e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.6581e-04 - val_loss: 5.1917e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 4.6530e-04 - val_loss: 4.8513e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.2922e-04 - val_loss: 4.9133e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.6583e-04 - val_loss: 5.0873e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 4.5011e-04 - val_loss: 5.3192e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 4.7008e-04 - val_loss: 4.3283e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.9241e-04 - val_loss: 4.8398e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.4693e-04 - val_loss: 4.4211e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.7976e-04 - val_loss: 4.9250e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.2076e-04 - val_loss: 4.8958e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 3.9715e-04 - val_loss: 4.7565e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.2316e-04 - val_loss: 3.8852e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.7423e-04 - val_loss: 4.3196e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 3.6967e-04 - val_loss: 4.0518e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 3.8133e-04 - val_loss: 4.1693e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4818e-04 - val_loss: 5.8246e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.0694e-04 - val_loss: 3.9674e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fea9b7000d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get reconstructed test data\n",
        "X_test_bilstm_reconstructed = bilstm_autoencoder.predict(X_test_lstm)\n",
        "\n",
        "# Compute reconstruction error (Mean Absolute Error)\n",
        "reconstruction_error_bilstm = np.mean(np.abs(X_test_lstm - X_test_bilstm_reconstructed), axis=(1, 2))\n",
        "\n",
        "# Display error statistics\n",
        "print(\"Bi-Directional LSTM Reconstruction Error - Min:\", reconstruction_error_bilstm.min())\n",
        "print(\"Bi-Directional LSTM Reconstruction Error - Max:\", reconstruction_error_bilstm.max())\n",
        "print(\"Bi-Directional LSTM Reconstruction Error - Mean:\", reconstruction_error_bilstm.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dR1Oj45X3V5",
        "outputId": "5faa1b37-3cdd-4e7f-fb5d-78052cf1d141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step\n",
            "Bi-Directional LSTM Reconstruction Error - Min: 0.007532922493437013\n",
            "Bi-Directional LSTM Reconstruction Error - Max: 0.0580078010794708\n",
            "Bi-Directional LSTM Reconstruction Error - Mean: 0.013159129417299447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define anomaly threshold\n",
        "threshold_bilstm = np.percentile(reconstruction_error_bilstm, 95)\n",
        "\n",
        "print(f\"Bi-Directional LSTM Anomaly Detection Threshold: {threshold_bilstm}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfihYwtUX8xt",
        "outputId": "9e64a74c-5609-437a-aa7b-32a915635ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bi-Directional LSTM Anomaly Detection Threshold: 0.0214388493749499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict anomalies\n",
        "y_pred_bilstm = [1 if e > threshold_bilstm else 0 for e in reconstruction_error_bilstm]\n",
        "\n",
        "# Evaluate Bi-Directional LSTM Performance\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(\"ğŸ”¹ Bi-Directional LSTM AutoEncoder Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred_bilstm))\n",
        "print(classification_report(y_test, y_pred_bilstm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4ur2oXXYBqa",
        "outputId": "82045b6b-e28a-4960-aeff-aa4b4741a531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ Bi-Directional LSTM AutoEncoder Performance:\n",
            "[[736   5]\n",
            " [314  51]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.99      0.82       741\n",
            "           1       0.91      0.14      0.24       365\n",
            "\n",
            "    accuracy                           0.71      1106\n",
            "   macro avg       0.81      0.57      0.53      1106\n",
            "weighted avg       0.77      0.71      0.63      1106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supervised Learning"
      ],
      "metadata": {
        "id": "X2lK8O-QZ3GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Drop DATETIME column\n",
        "X = df_attack.drop(columns=['DATETIME', 'ATT_FLAG'])\n",
        "y = df_attack['ATT_FLAG']\n",
        "\n",
        "# Apply SMOTE to oversample attack samples\n",
        "smote = SMOTE(sampling_strategy=0.5, random_state=42)  # 50% attack samples\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Check new class balance\n",
        "print(\"Class distribution after SMOTE:\")\n",
        "print(pd.Series(y_balanced).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "hETzrAKTZe4z",
        "outputId": "39f3d0e5-17af-451c-f7a4-e24f0c8bdc5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['DATETIME'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5126c5d8e9a8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Drop DATETIME column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATETIME'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ATT_FLAG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_attack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ATT_FLAG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['DATETIME'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_clf = XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict & Evaluate\n",
        "y_pred_xgb = xgb_clf.predict(X_test)\n",
        "\n",
        "print(\"ğŸ”¹ XGBoost Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred_xgb))\n",
        "print(classification_report(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAv6MNDhZkiL",
        "outputId": "f98664e9-5763-4520-fb02-0a13ae711771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ XGBoost Performance:\n",
            "[[739   2]\n",
            " [ 68 297]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.95       741\n",
            "           1       0.99      0.81      0.89       365\n",
            "\n",
            "    accuracy                           0.94      1106\n",
            "   macro avg       0.95      0.91      0.92      1106\n",
            "weighted avg       0.94      0.94      0.93      1106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [4, 6, 8],\n",
        "}\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search = GridSearchCV(XGBClassifier(random_state=42), param_grid, scoring='recall', cv=3)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Train model with best parameters\n",
        "best_xgb = XGBClassifier(**grid_search.best_params_, random_state=42)\n",
        "best_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict & Evaluate\n",
        "y_pred_best = best_xgb.predict(X_test)\n",
        "\n",
        "print(\"ğŸ”¹ XGBoost (Tuned) Performance:\")\n",
        "print(confusion_matrix(y_test, y_pred_best))\n",
        "print(classification_report(y_test, y_pred_best))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXPdJot_aGHV",
        "outputId": "67efb631-deac-4af8-942f-9bdee188d3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 300}\n",
            "ğŸ”¹ XGBoost (Tuned) Performance:\n",
            "[[733   8]\n",
            " [ 37 328]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       741\n",
            "           1       0.98      0.90      0.94       365\n",
            "\n",
            "    accuracy                           0.96      1106\n",
            "   macro avg       0.96      0.94      0.95      1106\n",
            "weighted avg       0.96      0.96      0.96      1106\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CPU Utilization for Tuned XGBoost"
      ],
      "metadata": {
        "id": "m7fH38EAhM4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the scaler (if not already loaded)\n",
        "import joblib\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "\n",
        "# Scale the test set\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Rebuild DataFrame with original column names\n",
        "X_test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n"
      ],
      "metadata": {
        "id": "YO1by5bWfR4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import time\n",
        "\n",
        "cpu_usages = []\n",
        "timings = []\n",
        "\n",
        "for i in range(20):\n",
        "  # Start measuring\n",
        "  cpu_start = psutil.cpu_percent(interval=None)\n",
        "  mem_start = psutil.virtual_memory().used / (1024 ** 2)  # in MB\n",
        "  start = time.perf_counter()\n",
        "\n",
        "  # Run your model\n",
        "  y_pred_xgb = best_xgb.predict(X_test_df)\n",
        "\n",
        "  # Stop measuring\n",
        "  end = time.perf_counter()\n",
        "  cpu_end = psutil.cpu_percent(interval=None)\n",
        "  mem_end = psutil.virtual_memory().used / (1024 ** 2)\n",
        "\n",
        "  cpu_avg = (cpu_start + cpu_end) / 2\n",
        "  elapsed_time = end - start\n",
        "\n",
        "  cpu_usages.append(cpu_avg)\n",
        "  timings.append(elapsed_time)\n",
        "\n",
        "  print(f\"Run {i+1:02d} â†’ CPU: {cpu_avg:.2f}%, Time: {elapsed_time:.4f} s\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\nğŸ” AEED Resource Usage Summary (20 runs):\")\n",
        "print(f\"ğŸ“Š Avg CPU Usage: {np.mean(cpu_usages):.2f}%\")\n",
        "print(f\"ğŸ“ˆ Std Dev CPU:   {np.std(cpu_usages):.2f}%\")\n",
        "print(f\"â±ï¸  Avg Time:      {np.mean(timings):.4f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaEZ5htcfArm",
        "outputId": "bb7839c3-ab3e-4800-ab45-4f2c5f7c970d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 01 â†’ CPU: 41.45%, Time: 0.0148 s\n",
            "Run 02 â†’ CPU: 50.00%, Time: 0.0136 s\n",
            "Run 03 â†’ CPU: 50.00%, Time: 0.0134 s\n",
            "Run 04 â†’ CPU: 50.00%, Time: 0.0133 s\n",
            "Run 05 â†’ CPU: 33.35%, Time: 0.0128 s\n",
            "Run 06 â†’ CPU: 50.00%, Time: 0.0125 s\n",
            "Run 07 â†’ CPU: 50.00%, Time: 0.0124 s\n",
            "Run 08 â†’ CPU: 50.00%, Time: 0.0123 s\n",
            "Run 09 â†’ CPU: 50.00%, Time: 0.0122 s\n",
            "Run 10 â†’ CPU: 50.00%, Time: 0.0132 s\n",
            "Run 11 â†’ CPU: 50.00%, Time: 0.0140 s\n",
            "Run 12 â†’ CPU: 50.00%, Time: 0.0141 s\n",
            "Run 13 â†’ CPU: 50.00%, Time: 0.0126 s\n",
            "Run 14 â†’ CPU: 33.35%, Time: 0.0126 s\n",
            "Run 15 â†’ CPU: 50.00%, Time: 0.0123 s\n",
            "Run 16 â†’ CPU: 50.00%, Time: 0.0126 s\n",
            "Run 17 â†’ CPU: 50.00%, Time: 0.0146 s\n",
            "Run 18 â†’ CPU: 50.00%, Time: 0.0129 s\n",
            "Run 19 â†’ CPU: 50.00%, Time: 0.0128 s\n",
            "Run 20 â†’ CPU: 50.00%, Time: 0.0125 s\n",
            "\n",
            "ğŸ” AEED Resource Usage Summary (20 runs):\n",
            "ğŸ“Š Avg CPU Usage: 47.91%\n",
            "ğŸ“ˆ Std Dev CPU:   5.20%\n",
            "â±ï¸  Avg Time:      0.0131 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(best_xgb, \"best_xgb.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfHEn9F2FOhU",
        "outputId": "aef72f35-1b7b-4e56-d0a5-5663a57fb881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best_xgb.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get feature importance\n",
        "importance = best_xgb.feature_importances_\n",
        "features = X_train.columns\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(features, importance)\n",
        "plt.xlabel(\"Feature Importance Score\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.title(\"ğŸ”¹ XGBoost Feature Importance for Cyberattack Detection\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "kh0qniM3bxF7",
        "outputId": "9eca3a9b-9c4b-4ea0-a49a-dce6b8a8808d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 128313 (\\N{SMALL BLUE DIAMOND}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop extra columns to match training features\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/CWDS_DEMO/BATADAL Datasets/BATADAL_test.csv\", parse_dates=['DATETIME'], dayfirst=True)\n",
        "X_test_unlabeled = df_test.drop(columns=['DATETIME', 'ATT_FLAG'], errors='ignore')\n",
        "\n",
        "# Ensure feature names match\n",
        "print(\"Features in X_train:\", list(X_train.columns))\n",
        "print(\"Features in X_test_unlabeled:\", list(X_test_unlabeled.columns))\n",
        "\n",
        "# Predict anomalies\n",
        "y_pred_test = best_xgb.predict(X_test_unlabeled)\n",
        "\n",
        "# Add predictions to dataset\n",
        "df_test['PREDICTED_ATTACK'] = y_pred_test\n",
        "\n",
        "# Show first few rows\n",
        "df_test.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "RFDdago8b5Io",
        "outputId": "c08f0282-a924-4f85-e0af-0bcc6359a75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features in X_train: ['L_T1', 'L_T2', 'L_T3', 'L_T4', 'L_T5', 'L_T6', 'L_T7', 'F_PU1', 'S_PU1', 'F_PU2', 'S_PU2', 'F_PU3', 'S_PU3', 'F_PU4', 'S_PU4', 'F_PU5', 'S_PU5', 'F_PU6', 'S_PU6', 'F_PU7', 'S_PU7', 'F_PU8', 'S_PU8', 'F_PU9', 'S_PU9', 'F_PU10', 'S_PU10', 'F_PU11', 'S_PU11', 'F_V2', 'S_V2', 'P_J280', 'P_J269', 'P_J300', 'P_J256', 'P_J289', 'P_J415', 'P_J302', 'P_J306', 'P_J307', 'P_J317', 'P_J14', 'P_J422']\n",
            "Features in X_test_unlabeled: ['L_T1', 'L_T2', 'L_T3', 'L_T4', 'L_T5', 'L_T6', 'L_T7', 'F_PU1', 'S_PU1', 'F_PU2', 'S_PU2', 'F_PU3', 'S_PU3', 'F_PU4', 'S_PU4', 'F_PU5', 'S_PU5', 'F_PU6', 'S_PU6', 'F_PU7', 'S_PU7', 'F_PU8', 'S_PU8', 'F_PU9', 'S_PU9', 'F_PU10', 'S_PU10', 'F_PU11', 'S_PU11', 'F_V2', 'S_V2', 'P_J280', 'P_J269', 'P_J300', 'P_J256', 'P_J289', 'P_J415', 'P_J302', 'P_J306', 'P_J307', 'P_J317', 'P_J14', 'P_J422']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-a07fed02ec22>:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_test = pd.read_csv(\"/content/drive/MyDrive/CWDS_DEMO/BATADAL Datasets/BATADAL_test.csv\", parse_dates=['DATETIME'], dayfirst=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             DATETIME  L_T1  L_T2  L_T3  L_T4  L_T5  L_T6  L_T7  F_PU1  S_PU1  \\\n",
              "0 2017-01-04 00:00:00  0.73  2.27  4.00  3.26  3.87  5.50  4.28  98.93    1.0   \n",
              "1 2017-01-04 01:00:00  0.69  2.25  4.53  3.26  3.84  5.50  4.78  97.95    1.0   \n",
              "2 2017-01-04 02:00:00  0.90  2.31  5.03  3.41  3.32  5.16  3.22  96.82    1.0   \n",
              "3 2017-01-04 03:00:00  1.11  2.54  5.16  3.97  2.82  5.01  2.54  96.76    1.0   \n",
              "4 2017-01-04 04:00:00  1.27  2.99  4.94  4.27  2.35  5.38  3.41  94.77    1.0   \n",
              "\n",
              "   ...  P_J289  P_J415  P_J302  P_J306  P_J307  P_J317  P_J14  P_J422  \\\n",
              "0  ...   26.74   84.52   19.43   83.27   19.33   71.33  29.61   28.71   \n",
              "1  ...   26.73   85.04   25.97   64.22   25.86   73.79  29.63   28.73   \n",
              "2  ...   26.89   87.16   29.18   63.81   29.18   59.05  29.80   28.90   \n",
              "3  ...   28.23   88.83   26.53   63.42   26.41   70.92  30.80   29.90   \n",
              "4  ...   31.32   69.55   27.46   63.43   27.34   70.88  33.61   32.71   \n",
              "\n",
              "   ATT_FLAG  PREDICTED_ATTACK  \n",
              "0       0.0                 0  \n",
              "1       0.0                 0  \n",
              "2       0.0                 0  \n",
              "3       0.0                 0  \n",
              "4       0.0                 0  \n",
              "\n",
              "[5 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b5146ad-44cd-4349-82eb-6ded9f9077e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATETIME</th>\n",
              "      <th>L_T1</th>\n",
              "      <th>L_T2</th>\n",
              "      <th>L_T3</th>\n",
              "      <th>L_T4</th>\n",
              "      <th>L_T5</th>\n",
              "      <th>L_T6</th>\n",
              "      <th>L_T7</th>\n",
              "      <th>F_PU1</th>\n",
              "      <th>S_PU1</th>\n",
              "      <th>...</th>\n",
              "      <th>P_J289</th>\n",
              "      <th>P_J415</th>\n",
              "      <th>P_J302</th>\n",
              "      <th>P_J306</th>\n",
              "      <th>P_J307</th>\n",
              "      <th>P_J317</th>\n",
              "      <th>P_J14</th>\n",
              "      <th>P_J422</th>\n",
              "      <th>ATT_FLAG</th>\n",
              "      <th>PREDICTED_ATTACK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-04 00:00:00</td>\n",
              "      <td>0.73</td>\n",
              "      <td>2.27</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.87</td>\n",
              "      <td>5.50</td>\n",
              "      <td>4.28</td>\n",
              "      <td>98.93</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26.74</td>\n",
              "      <td>84.52</td>\n",
              "      <td>19.43</td>\n",
              "      <td>83.27</td>\n",
              "      <td>19.33</td>\n",
              "      <td>71.33</td>\n",
              "      <td>29.61</td>\n",
              "      <td>28.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-04 01:00:00</td>\n",
              "      <td>0.69</td>\n",
              "      <td>2.25</td>\n",
              "      <td>4.53</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.84</td>\n",
              "      <td>5.50</td>\n",
              "      <td>4.78</td>\n",
              "      <td>97.95</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26.73</td>\n",
              "      <td>85.04</td>\n",
              "      <td>25.97</td>\n",
              "      <td>64.22</td>\n",
              "      <td>25.86</td>\n",
              "      <td>73.79</td>\n",
              "      <td>29.63</td>\n",
              "      <td>28.73</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-04 02:00:00</td>\n",
              "      <td>0.90</td>\n",
              "      <td>2.31</td>\n",
              "      <td>5.03</td>\n",
              "      <td>3.41</td>\n",
              "      <td>3.32</td>\n",
              "      <td>5.16</td>\n",
              "      <td>3.22</td>\n",
              "      <td>96.82</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26.89</td>\n",
              "      <td>87.16</td>\n",
              "      <td>29.18</td>\n",
              "      <td>63.81</td>\n",
              "      <td>29.18</td>\n",
              "      <td>59.05</td>\n",
              "      <td>29.80</td>\n",
              "      <td>28.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-04 03:00:00</td>\n",
              "      <td>1.11</td>\n",
              "      <td>2.54</td>\n",
              "      <td>5.16</td>\n",
              "      <td>3.97</td>\n",
              "      <td>2.82</td>\n",
              "      <td>5.01</td>\n",
              "      <td>2.54</td>\n",
              "      <td>96.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>28.23</td>\n",
              "      <td>88.83</td>\n",
              "      <td>26.53</td>\n",
              "      <td>63.42</td>\n",
              "      <td>26.41</td>\n",
              "      <td>70.92</td>\n",
              "      <td>30.80</td>\n",
              "      <td>29.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-04 04:00:00</td>\n",
              "      <td>1.27</td>\n",
              "      <td>2.99</td>\n",
              "      <td>4.94</td>\n",
              "      <td>4.27</td>\n",
              "      <td>2.35</td>\n",
              "      <td>5.38</td>\n",
              "      <td>3.41</td>\n",
              "      <td>94.77</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>31.32</td>\n",
              "      <td>69.55</td>\n",
              "      <td>27.46</td>\n",
              "      <td>63.43</td>\n",
              "      <td>27.34</td>\n",
              "      <td>70.88</td>\n",
              "      <td>33.61</td>\n",
              "      <td>32.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 46 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b5146ad-44cd-4349-82eb-6ded9f9077e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b5146ad-44cd-4349-82eb-6ded9f9077e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b5146ad-44cd-4349-82eb-6ded9f9077e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe167779-80eb-4075-a2ca-1faff33aa6b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe167779-80eb-4075-a2ca-1faff33aa6b5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe167779-80eb-4075-a2ca-1faff33aa6b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Retrain XGBoost with best parameters\n",
        "best_xgb = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=6, random_state=42)\n",
        "best_xgb.fit(X_train, y_train)\n",
        "\n",
        "print(\"âœ… Model retrained successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv3CzXvDdx_D",
        "outputId": "897d31f4-5a90-4e3b-f5f8-6f951c42a90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model retrained successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure only features used during training are present\n",
        "expected_features = X_train.columns  # Get the exact training features\n",
        "X_test_unlabeled = df_test[expected_features]  # Select only those columns\n",
        "\n",
        "# Ensure the features match\n",
        "print(\"âœ… Features now match correctly!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdyspN3BeBGU",
        "outputId": "93ef52e3-7d90-49a6-cb6a-f493fb0bbf22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Features now match correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure test dataset has the same feature order as training\n",
        "X_test_unlabeled = X_test_unlabeled[X_train.columns]  # Reorder to match training\n",
        "\n",
        "# Verify column order\n",
        "print(\"Training Features:\", list(X_train.columns))\n",
        "print(\"Test Features:\", list(X_test_unlabeled.columns))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lF4TDjse0xg",
        "outputId": "a29a713b-4a14-4abb-89b6-673c20cebb56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features: ['L_T1', 'L_T2', 'L_T3', 'L_T4', 'L_T5', 'L_T6', 'L_T7', 'F_PU1', 'S_PU1', 'F_PU2', 'S_PU2', 'F_PU3', 'S_PU3', 'F_PU4', 'S_PU4', 'F_PU5', 'S_PU5', 'F_PU6', 'S_PU6', 'F_PU7', 'S_PU7', 'F_PU8', 'S_PU8', 'F_PU9', 'S_PU9', 'F_PU10', 'S_PU10', 'F_PU11', 'S_PU11', 'F_V2', 'S_V2', 'P_J280', 'P_J269', 'P_J300', 'P_J256', 'P_J289', 'P_J415', 'P_J302', 'P_J306', 'P_J307', 'P_J317', 'P_J14', 'P_J422']\n",
            "Test Features: ['L_T1', 'L_T2', 'L_T3', 'L_T4', 'L_T5', 'L_T6', 'L_T7', 'F_PU1', 'S_PU1', 'F_PU2', 'S_PU2', 'F_PU3', 'S_PU3', 'F_PU4', 'S_PU4', 'F_PU5', 'S_PU5', 'F_PU6', 'S_PU6', 'F_PU7', 'S_PU7', 'F_PU8', 'S_PU8', 'F_PU9', 'S_PU9', 'F_PU10', 'S_PU10', 'F_PU11', 'S_PU11', 'F_V2', 'S_V2', 'P_J280', 'P_J269', 'P_J300', 'P_J256', 'P_J289', 'P_J415', 'P_J302', 'P_J306', 'P_J307', 'P_J317', 'P_J14', 'P_J422']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict anomalies\n",
        "df_test['PREDICTED_ATTACK'] = best_xgb.predict(X_test_unlabeled)\n",
        "\n",
        "# Show first few rows with predictions\n",
        "display(df_test.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "2BpdIcQTfYDH",
        "outputId": "cb26b47e-4f09-459a-cdae-731ceb0b2b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             DATETIME  L_T1  L_T2  L_T3  L_T4  L_T5  L_T6  L_T7  F_PU1  S_PU1  \\\n",
              "0 2017-01-04 00:00:00  0.73  2.27  4.00  3.26  3.87  5.50  4.28  98.93    1.0   \n",
              "1 2017-01-04 01:00:00  0.69  2.25  4.53  3.26  3.84  5.50  4.78  97.95    1.0   \n",
              "2 2017-01-04 02:00:00  0.90  2.31  5.03  3.41  3.32  5.16  3.22  96.82    1.0   \n",
              "3 2017-01-04 03:00:00  1.11  2.54  5.16  3.97  2.82  5.01  2.54  96.76    1.0   \n",
              "4 2017-01-04 04:00:00  1.27  2.99  4.94  4.27  2.35  5.38  3.41  94.77    1.0   \n",
              "\n",
              "   ...  P_J289  P_J415  P_J302  P_J306  P_J307  P_J317  P_J14  P_J422  \\\n",
              "0  ...   26.74   84.52   19.43   83.27   19.33   71.33  29.61   28.71   \n",
              "1  ...   26.73   85.04   25.97   64.22   25.86   73.79  29.63   28.73   \n",
              "2  ...   26.89   87.16   29.18   63.81   29.18   59.05  29.80   28.90   \n",
              "3  ...   28.23   88.83   26.53   63.42   26.41   70.92  30.80   29.90   \n",
              "4  ...   31.32   69.55   27.46   63.43   27.34   70.88  33.61   32.71   \n",
              "\n",
              "   ATT_FLAG  PREDICTED_ATTACK  \n",
              "0       0.0                 0  \n",
              "1       0.0                 0  \n",
              "2       0.0                 0  \n",
              "3       0.0                 0  \n",
              "4       0.0                 0  \n",
              "\n",
              "[5 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e70dc811-fb60-4af7-bcf9-f09d4b10db55\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATETIME</th>\n",
              "      <th>L_T1</th>\n",
              "      <th>L_T2</th>\n",
              "      <th>L_T3</th>\n",
              "      <th>L_T4</th>\n",
              "      <th>L_T5</th>\n",
              "      <th>L_T6</th>\n",
              "      <th>L_T7</th>\n",
              "      <th>F_PU1</th>\n",
              "      <th>S_PU1</th>\n",
              "      <th>...</th>\n",
              "      <th>P_J289</th>\n",
              "      <th>P_J415</th>\n",
              "      <th>P_J302</th>\n",
              "      <th>P_J306</th>\n",
              "      <th>P_J307</th>\n",
              "      <th>P_J317</th>\n",
              "      <th>P_J14</th>\n",
              "      <th>P_J422</th>\n",
              "      <th>ATT_FLAG</th>\n",
              "      <th>PREDICTED_ATTACK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-04 00:00:00</td>\n",
              "      <td>0.73</td>\n",
              "      <td>2.27</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.87</td>\n",
              "      <td>5.50</td>\n",
              "      <td>4.28</td>\n",
              "      <td>98.93</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26.74</td>\n",
              "      <td>84.52</td>\n",
              "      <td>19.43</td>\n",
              "      <td>83.27</td>\n",
              "      <td>19.33</td>\n",
              "      <td>71.33</td>\n",
              "      <td>29.61</td>\n",
              "      <td>28.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-04 01:00:00</td>\n",
              "      <td>0.69</td>\n",
              "      <td>2.25</td>\n",
              "      <td>4.53</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.84</td>\n",
              "      <td>5.50</td>\n",
              "      <td>4.78</td>\n",
              "      <td>97.95</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26.73</td>\n",
              "      <td>85.04</td>\n",
              "      <td>25.97</td>\n",
              "      <td>64.22</td>\n",
              "      <td>25.86</td>\n",
              "      <td>73.79</td>\n",
              "      <td>29.63</td>\n",
              "      <td>28.73</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-04 02:00:00</td>\n",
              "      <td>0.90</td>\n",
              "      <td>2.31</td>\n",
              "      <td>5.03</td>\n",
              "      <td>3.41</td>\n",
              "      <td>3.32</td>\n",
              "      <td>5.16</td>\n",
              "      <td>3.22</td>\n",
              "      <td>96.82</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26.89</td>\n",
              "      <td>87.16</td>\n",
              "      <td>29.18</td>\n",
              "      <td>63.81</td>\n",
              "      <td>29.18</td>\n",
              "      <td>59.05</td>\n",
              "      <td>29.80</td>\n",
              "      <td>28.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-04 03:00:00</td>\n",
              "      <td>1.11</td>\n",
              "      <td>2.54</td>\n",
              "      <td>5.16</td>\n",
              "      <td>3.97</td>\n",
              "      <td>2.82</td>\n",
              "      <td>5.01</td>\n",
              "      <td>2.54</td>\n",
              "      <td>96.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>28.23</td>\n",
              "      <td>88.83</td>\n",
              "      <td>26.53</td>\n",
              "      <td>63.42</td>\n",
              "      <td>26.41</td>\n",
              "      <td>70.92</td>\n",
              "      <td>30.80</td>\n",
              "      <td>29.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-04 04:00:00</td>\n",
              "      <td>1.27</td>\n",
              "      <td>2.99</td>\n",
              "      <td>4.94</td>\n",
              "      <td>4.27</td>\n",
              "      <td>2.35</td>\n",
              "      <td>5.38</td>\n",
              "      <td>3.41</td>\n",
              "      <td>94.77</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>31.32</td>\n",
              "      <td>69.55</td>\n",
              "      <td>27.46</td>\n",
              "      <td>63.43</td>\n",
              "      <td>27.34</td>\n",
              "      <td>70.88</td>\n",
              "      <td>33.61</td>\n",
              "      <td>32.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 46 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e70dc811-fb60-4af7-bcf9-f09d4b10db55')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e70dc811-fb60-4af7-bcf9-f09d4b10db55 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e70dc811-fb60-4af7-bcf9-f09d4b10db55');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6121aea3-a101-41a4-b0e4-4e897ff353ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6121aea3-a101-41a4-b0e4-4e897ff353ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6121aea3-a101-41a4-b0e4-4e897ff353ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['PREDICTED_ATTACK'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "xm5JQ3uWfwk9",
        "outputId": "ef8bffad-d07d-46d7-f410-d86bbec5e8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PREDICTED_ATTACK\n",
              "0    2027\n",
              "1      62\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PREDICTED_ATTACK</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataset with predictions\n",
        "df_test.to_csv(\"/content/BATADAL_XGBoost_Predictions.csv\", index=False)\n",
        "\n",
        "print(\"âœ… File saved! Ready for download.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l61x-kU7g65o",
        "outputId": "189700c1-a7db-4624-977b-35feb3e78e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… File saved! Ready for download.\n"
          ]
        }
      ]
    }
  ]
}